Implementing the KMP Algorithm
Code the Knuth-Morris-Pratt (KMP) algorithm in C# for pattern searching which pre-processes the pattern to reduce the number of comparisons. Explain how this pre-processing improves the search time compared to the naive approach.

public class KMPAlgorithm {

    // Method to perform KMP search
    void KMPSearch(String pattern, String text) {
        int M = pattern.length();
        int N = text.length();

        // Create lps[] that will hold the longest prefix suffix values for pattern
        int[] lps = new int[M];
        int j = 0;  // index for pattern[]

        // Preprocess the pattern (calculate lps[] array)
        computeLPSArray(pattern, M, lps);

        int i = 0;  // index for text[]
        while (i < N) {
            if (pattern.charAt(j) == text.charAt(i)) {
                j++;
                i++;
            }

            if (j == M) {
                System.out.println("Found pattern at index " + (i - j));
                j = lps[j - 1];
            }

            // mismatch after j matches
            else if (i < N && pattern.charAt(j) != text.charAt(i)) {
                // Do not match lps[0..lps[j-1]] characters, they will match anyway
                if (j != 0)
                    j = lps[j - 1];
                else
                    i = i + 1;
            }
        }
    }

    // Method to compute the longest prefix suffix (lps) array
    void computeLPSArray(String pattern, int M, int[] lps) {
        // length of the previous longest prefix suffix
        int length = 0;
        int i = 1;
        lps[0] = 0;  // lps[0] is always 0

        // the loop calculates lps[i] for i = 1 to M-1
        while (i < M) {
            if (pattern.charAt(i) == pattern.charAt(length)) {
                length++;
                lps[i] = length;
                i++;
            } else {
                // This is tricky. Consider the example.
                // AAACAAAA and i = 7. The idea is similar
                // to search step.
                if (length != 0) {
                    length = lps[length - 1];
                } else {
                    lps[i] = 0;
                    i++;
                }
            }
        }
    }

    // Main method to test the KMP algorithm
    public static void main(String[] args) {
        KMPAlgorithm kmp = new KMPAlgorithm();
        String text = "ABABDABACDABABCABAB";
        String pattern = "ABABCABAB";
        kmp.KMPSearch(pattern, text);
    }
}

Explanation of the Preprocessing and Search Time Improvement
Preprocessing Step (Computing LPS Array):

The preprocessing step involves creating an array lps (Longest Prefix Suffix) which is used to skip characters while matching.
The lps array is computed in O(M) time, where M is the length of the pattern. The lps array stores the length of the longest proper prefix which is also a suffix for the substring pattern[0...i].
This allows the algorithm to avoid re-evaluating characters that have already been matched, thus reducing the number of comparisons.
Search Step:

During the search, for each mismatch after a certain number of matches, the algorithm uses the lps array to determine the next positions to continue matching without rechecking characters that are already known to match.
This significantly reduces the number of comparisons, especially for patterns with repetitive subpatterns.
Comparison with Naive Approach:

The naive approach to pattern searching involves checking the pattern at every possible position in the text, which can lead to O(M*N) comparisons in the worst case, where N is the length of the text and M is the length of the pattern.
KMP, on the other hand, ensures that each character of the text is compared at most once, achieving a time complexity of O(N) for the search phase. The total complexity, including preprocessing, is O(M + N).
By preprocessing the pattern and using the lps array, KMP avoids unnecessary comparisons, making it much more efficient than the naive approach for many practical applications

 
  task 2:Rabin-Karp Substring Search
Implement the Rabin-Karp algorithm for substring search using a rolling hash. Discuss the impact of hash collisions on the algorithm's performance and how to handle them.

public class RabinKarpAlgorithm {

    // d is the number of characters in the input alphabet
    public final static int d = 256;

    /* 
     * pat  -> pattern
     * txt  -> text
     * q    -> A prime number
     */
    static void search(String pat, String txt, int q) {
        int M = pat.length();
        int N = txt.length();
        int i, j;
        int p = 0; // hash value for pattern
        int t = 0; // hash value for txt
        int h = 1;

        // The value of h would be "pow(d, M-1)%q"
        for (i = 0; i < M - 1; i++)
            h = (h * d) % q;

        // Calculate the hash value of pattern and first window of text
        for (i = 0; i < M; i++) {
            p = (d * p + pat.charAt(i)) % q;
            t = (d * t + txt.charAt(i)) % q;
        }

        // Slide the pattern over text one by one
        for (i = 0; i <= N - M; i++) {

            // Check the hash values of current window of text and pattern.
            // If the hash values match then only check for characters one by one
            if (p == t) {
                /* Check for characters one by one */
                for (j = 0; j < M; j++) {
                    if (txt.charAt(i + j) != pat.charAt(j))
                        break;
                }

                // if p == t and pat[0...M-1] = txt[i, i+1, ...i+M-1]
                if (j == M)
                    System.out.println("Pattern found at index " + i);
            }

            // Calculate hash value for next window of text: Remove leading digit,
            // add trailing digit
            if (i < N - M) {
                t = (d * (t - txt.charAt(i) * h) + txt.charAt(i + M)) % q;

                // We might get negative value of t, converting it to positive
                if (t < 0)
                    t = (t + q);
            }
        }
    }

    /* Driver program to test above function */
    public static void main(String[] args) {
        String txt = "GEEKS FOR GEEKS";
        String pat = "GEEK";
        int q = 101; // A prime number
        search(pat, txt, q);
    }
}
Explanation of Hash Collisions and Their Impact on Performance
Hash Collisions:
Hash collisions occur when two different substrings produce the same hash value. In the context of the Rabin-Karp algorithm, this means that the hash value of the pattern matches the hash value of a substring in the text, but the substrings themselves are not identical.
Hash collisions can lead to false positives, where the algorithm wrongly identifies a match. When a hash collision occurs, the algorithm must perform a direct comparison of the substrings to verify the match, which can increase the number of comparisons and thus affect performance.
Impact on Performance:
The expected time complexity of the Rabin-Karp algorithm is O(N + M) in the best case, where N is the length of the text and M is the length of the pattern. This assumes that hash collisions are rare and thus only a few direct substring comparisons are needed.
In the worst case, where hash collisions are frequent, the algorithm may degrade to O(NM) time complexity, similar to the naive approach, because many direct comparisons may be required.
Handling Hash Collisions:
Choosing a good hash function and a large prime number for modulo operations can minimize the likelihood of hash collisions.
A rolling hash function that distributes hash values uniformly across possible substrings can help reduce collisions.
When a hash collision occurs, the algorithm performs a direct comparison of the substrings to ensure they are actually the same. This additional step ensures correctness but may affect performance.
By efficiently handling hash collisions and using a good hash function, the Rabin-Karp algorithm can perform well in practice, especially for large texts with small patterns.

Task 3:Boyer-Moore Algorithm Application
Use the Boyer-Moore algorithm to write a function that finds the last occurrence of a substring in a given string and returns its index. Explain why this algorithm can outperform others in certain scenarios.

import java.util.Arrays;

public class BoyerMooreAlgorithm {

    // The Boyer-Moore algorithm's bad character heuristic
    static int[] preprocessBadCharacterHeuristic(String pattern) {
        int[] badChar = new int[256];
        Arrays.fill(badChar, -1);
        for (int i = 0; i < pattern.length(); i++) {
            badChar[(int) pattern.charAt(i)] = i;
        }
        return badChar;
    }

    // The Boyer-Moore algorithm's good suffix heuristic
    static void preprocessGoodSuffixHeuristic(String pattern, int[] shift, int[] bpos) {
        int m = pattern.length();
        int i = m, j = m + 1;
        bpos[i] = j;
        while (i > 0) {
            while (j <= m && pattern.charAt(i - 1) != pattern.charAt(j - 1)) {
                if (shift[j] == 0) {
                    shift[j] = j - i;
                }
                j = bpos[j];
            }
            i--;
            j--;
            bpos[i] = j;
        }
        j = bpos[0];
        for (i = 0; i <= m; i++) {
            if (shift[i] == 0) {
                shift[i] = j;
            }
            if (i == j) {
                j = bpos[j];
            }
        }
    }

    // Function to find the last occurrence of the pattern in the text
    static int boyerMooreSearchLastOccurrence(String text, String pattern) {
        int m = pattern.length();
        int n = text.length();

        int[] badChar = preprocessBadCharacterHeuristic(pattern);
        int[] shift = new int[m + 1];
        int[] bpos = new int[m + 1];
        Arrays.fill(shift, 0);

        preprocessGoodSuffixHeuristic(pattern, shift, bpos);

        int s = 0;
        int lastIndex = -1;

        while (s <= (n - m)) {
            int j = m - 1;
            while (j >= 0 && pattern.charAt(j) == text.charAt(s + j)) {
                j--;
            }
            if (j < 0) {
                lastIndex = s;
                s += (s + m < n) ? m - badChar[text.charAt(s + m)] : 1;
            } else {
                s += Math.max(shift[j + 1], j - badChar[text.charAt(s + j)]);
            }
        }

        return lastIndex;
    }

    public static void main(String[] args) {
        String text = "ABAAABCD";
        String pattern = "ABC";
        int lastIndex = boyerMooreSearchLastOccurrence(text, pattern);
        if (lastIndex == -1) {
            System.out.println("Pattern not found");
        } else {
            System.out.println("Last occurrence of pattern is at index " + lastIndex);
        }
    }
}
Explanation of the Boyer-Moore Algorithm's Performance
The Boyer-Moore algorithm can outperform other string matching algorithms in certain scenarios due to its use of two heuristics:

Bad Character Heuristic:

This heuristic preprocesses the pattern to create a table that stores the last occurrence of each character in the pattern.
During the search, if a mismatch occurs, the algorithm uses this table to skip over portions of the text where mismatches are guaranteed.
Good Suffix Heuristic:

This heuristic preprocesses the pattern to determine shifts based on matching suffixes.
If a mismatch occurs, the algorithm can shift the pattern so that a previously matched suffix aligns with a similar suffix in the text or skips over parts where no match is possible.
Advantages of Boyer-Moore Algorithm:
Efficient Skipping:

The Boyer-Moore algorithm can skip large sections of the text, making it more efficient, especially when the alphabet size is large or the pattern is relatively long compared to the text.
Right-to-Left Scanning:

By scanning the pattern from right to left, the algorithm can often find mismatches earlier and skip more characters, reducing the total number of comparisons.
Sublinear Time Complexity:

In the best-case scenario, the Boyer-Moore algorithm can achieve sublinear time complexity, O(N/M), where N is the length of the text and M is the length of the pattern. This is because it can skip sections of the text without checking every character.
These features make the Boyer-Moore algorithm particularly powerful for large texts and situations where the pattern has unique or infrequent characters.












